{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.layers import LSTM, Input, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import DatasetDict, Dataset"
      ],
      "metadata": {
        "id": "4cmD4U6laVyK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(word2vec = True):\n",
        "  data = pd.read_csv(\"spam_ham_dataset.csv\")\n",
        "  data = data.drop([\"Unnamed: 0\"], axis=1)\n",
        "  if word2vec:\n",
        "    data['text_clean'] = data['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
        "    texts = data[\"text_clean\"]\n",
        "  else:\n",
        "    texts = data[\"text\"]\n",
        "  labels = data[\"label_num\"]\n",
        "  print(data.shape)\n",
        "  return data, texts, labels"
      ],
      "metadata": {
        "id": "YwWBSkr9eArj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, texts, labels = load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX6TSqIMeqKb",
        "outputId": "0200fbe2-c7f1-4085-8c72-71ed8102e0e9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5171, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby('label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "EotZKb4cec3t",
        "outputId": "a46c3360-c78f-4786-b0db-47ce868b9333"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec with Linear Regression"
      ],
      "metadata": {
        "id": "8tLYd97Tbjuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.Word2Vec(sentences=texts, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Average word vectors for each document\n",
        "def document_vector(doc):\n",
        "    doc = [word for word in doc if word in model.wv.index_to_key]\n",
        "    return np.mean(model.wv[doc], axis=0)\n",
        "\n",
        "X = np.array([document_vector(doc) for doc in texts])\n",
        "y = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b07UZfLNjrU",
        "outputId": "5eea9f58-4101-47a9-8fb3-eef91d2b9dba"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4136, 100)\n",
            "(1035, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "SlhqNFdZa9nd",
        "outputId": "5c0aee67-8b8a-4ca0-bdb7-5c55eee543df"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions)\n",
        "f1 = f1_score(y_test, predictions)\n",
        "print(f'Accuracy: {accuracy} \\n Precision: {precision} \\n Recall: {recall} \\n F1: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K83A8upvN0HX",
        "outputId": "bd218218-df0c-4150-e719-44b7ae4380c5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9642512077294686 \n",
            " Precision: 0.9238410596026491 \n",
            " Recall: 0.9522184300341296 \n",
            " F1: 0.9378151260504202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN"
      ],
      "metadata": {
        "id": "DOroZqoCe3_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data, texts, labels = load_data(word2vec=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej5u8j_skqQ-",
        "outputId": "6f46c3ae-7967-4c00-91d5-63aa5a93a3db"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5171, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "word_index = tokenizer.word_index\n",
        "data = pad_sequences(sequences, maxlen=100)"
      ],
      "metadata": {
        "id": "d2_yA1x5Nn30"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "b1hlmGuiPy6h"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(word_index) + 1, output_dim=128, input_length=100))\n",
        "model.add(SimpleRNN(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZoukBcqc8TD",
        "outputId": "e7dec143-10a8-4725-c7ad-907c1fa55ebe"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "130/130 [==============================] - 34s 239ms/step - loss: 0.4019 - accuracy: 0.8044 - val_loss: 0.1927 - val_accuracy: 0.9208\n",
            "Epoch 2/5\n",
            "130/130 [==============================] - 23s 181ms/step - loss: 0.0473 - accuracy: 0.9862 - val_loss: 0.0983 - val_accuracy: 0.9614\n",
            "Epoch 3/5\n",
            "130/130 [==============================] - 18s 135ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0796 - val_accuracy: 0.9691\n",
            "Epoch 4/5\n",
            "130/130 [==============================] - 17s 134ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.1024 - val_accuracy: 0.9633\n",
            "Epoch 5/5\n",
            "130/130 [==============================] - 17s 126ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0889 - val_accuracy: 0.9643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6b5873b640>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test) > 0.5\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions)\n",
        "f1 = f1_score(y_test, predictions)\n",
        "print(f'Accuracy: {accuracy} \\n Precision: {precision} \\n Recall: {recall} \\n F1: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ys90iJtNv_6",
        "outputId": "d08393a0-4787-4211-f210-5d1906c65f74"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 0s 9ms/step\n",
            "Accuracy: 0.9642512077294686 \n",
            " Precision: 0.9324324324324325 \n",
            " Recall: 0.9419795221843004 \n",
            " F1: 0.937181663837012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seq2Seq - encoder decoder lstm"
      ],
      "metadata": {
        "id": "M20iF6v5fKaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape=(100,))\n",
        "x = Embedding(len(word_index) + 1, 128)(encoder_inputs)\n",
        "encoder = LSTM(128, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(100,))\n",
        "x = Embedding(len(word_index) + 1, 128)(decoder_inputs)\n",
        "decoder_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(x, initial_state=encoder_states)\n",
        "decoder_dense = Dense(1, activation='sigmoid')\n",
        "outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit([X_train, X_train], y_train, epochs=5, validation_data=([X_test, X_test], y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRjwVk9PfGMW",
        "outputId": "560ab547-0bae-4c92-9c4c-787a175c2f6e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "130/130 [==============================] - 72s 495ms/step - loss: 0.3296 - accuracy: 0.8636 - val_loss: 0.3364 - val_accuracy: 0.8784\n",
            "Epoch 2/5\n",
            "130/130 [==============================] - 55s 424ms/step - loss: 0.1304 - accuracy: 0.9667 - val_loss: 0.1691 - val_accuracy: 0.9478\n",
            "Epoch 3/5\n",
            "130/130 [==============================] - 49s 378ms/step - loss: 0.0574 - accuracy: 0.9887 - val_loss: 0.1009 - val_accuracy: 0.9786\n",
            "Epoch 4/5\n",
            "130/130 [==============================] - 45s 347ms/step - loss: 0.0161 - accuracy: 0.9978 - val_loss: 0.1771 - val_accuracy: 0.9666\n",
            "Epoch 5/5\n",
            "130/130 [==============================] - 47s 358ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.2057 - val_accuracy: 0.9702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6b58a72440>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [np.max(x) for x in (model.predict([X_test, X_test]) > 0.5)]\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions)\n",
        "f1 = f1_score(y_test, predictions)\n",
        "print(f'Accuracy: {accuracy} \\n Precision: {precision} \\n Recall: {recall} \\n F1: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWNd-CasN23-",
        "outputId": "b1334027-35bd-4211-a2ab-16c8de9317d0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 2s 53ms/step\n",
            "Accuracy: 0.9729468599033816 \n",
            " Precision: 0.9715302491103203 \n",
            " Recall: 0.931740614334471 \n",
            " F1: 0.9512195121951219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWOjeI0pStMq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}